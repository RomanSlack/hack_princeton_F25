# Daedalus API Key (required when LLM_PROVIDER=daedalus)
DEDALUS_API_KEY=your_daedalus_api_key_here

# OpenAI API Key (required when LLM_PROVIDER=openai, also used for chat functionality)
OPENAI_API_KEY=your_openai_api_key_here

# LLM Provider: "daedalus" (uses Daedalus Labs proxy) or "openai" (direct OpenAI API)
# - daedalus: Uses Daedalus Labs with MCP server support and multi-provider access
# - openai: Direct OpenAI API calls with function calling for web search
LLM_PROVIDER=daedalus

# Minimum time between steps (seconds)
# Set to 0 for maximum speed (steps start immediately after completion)
STEP_DELAY=6.0

# Default model for agents (can be overridden per agent in frontend)
# For daedalus provider: openai/gpt-4o-mini, anthropic/claude-3.5-haiku, google/gemini-flash-1.5, openai/gpt-4o, anthropic/claude-3.5-sonnet
# For openai provider: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
DEFAULT_MODEL=openai/gpt-4o-mini

# LLM timeout in seconds (if agent doesn't respond in time, skip their turn)
LLM_TIMEOUT=10.0

# ============================================================================
# Snowflake Configuration (Optional - for log persistence)
# ============================================================================
# Run ./setup_snowflake.sh to provision Snowflake resources via CLI
# Uncomment and configure these values after running setup

# SNOWFLAKE_ACCOUNT=your_account.region
# SNOWFLAKE_USER=log_ingest

# Authentication: Use EITHER password OR token (PAT), not both
# SNOWFLAKE_PASSWORD=your_password
# SNOWFLAKE_TOKEN=your_personal_access_token

# SNOWFLAKE_DATABASE=LOG_DB
# SNOWFLAKE_SCHEMA=RAW
# SNOWFLAKE_WAREHOUSE=LOG_WH
# SNOWFLAKE_ROLE=LOG_INGESTOR

# Snowflake logging settings
# SNOWFLAKE_ENABLED=true
# SNOWFLAKE_BATCH_SIZE=100
# SNOWFLAKE_FLUSH_INTERVAL=5
